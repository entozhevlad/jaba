version: "3.9"

services:
  arkasha:
    build: .
    image: arkasha-api
    ports:
      - "8080:8080"
    volumes:
      - ./data:/app/data

  spark-master:
    image: bitnami/spark:3.5
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_NO_DAEMONIZE=true
      - HADOOP_USER_NAME=root
      - SPARK_CONF_DIR=/app/conf
    ports:
      - "7077:7077"
      - "8081:8080" # UI
    volumes:
      - .:/app
    working_dir: /app

  spark-worker:
    image: bitnami/spark:3.5
    container_name: spark-worker
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_NO_DAEMONIZE=true
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - HADOOP_USER_NAME=root
      - SPARK_CONF_DIR=/app/conf
    ports:
      - "8082:8081"
    volumes:
      - .:/app
    working_dir: /app

  spark-lab2:
    image: bitnami/spark:3.5
    container_name: spark-lab2
    depends_on:
      - spark-master
      - spark-worker
    working_dir: /app
    user: "0:0"                      # можно убрать, если не нужен root
    volumes:
      - .:/app
      - ./conf:/app/conf             # <-- тут лежит core-site.xml
      - ./spark-warehouse:/app/spark-warehouse
    environment:
      - HOME=/tmp
      - SPARK_CONF_DIR=/app/conf     # <-- важно
      - USER=spark
      - SPARK_USER=spark
      - HADOOP_USER_NAME=spark
      # РАННИЕ JVM-параметры, чтобы UnixLoginModule не упал на null name
      - JAVA_TOOL_OPTIONS=-Duser.name=spark -Dhadoop.user.name=spark
    entrypoint:
      [
        "/opt/bitnami/spark/bin/spark-submit",
        "--master", "spark://spark-master:7077",
        "--class", "com.example.kvdb.apihttp.ArkashaApiApplication",

        "--conf", "spark.driver.host=spark-lab2",
        "--conf", "spark.driver.bindAddress=0.0.0.0",
        "--conf", "spark.jars.ivy=/tmp/ivy",

        # дублируем важное, но теперь это уже подхватится после core-site.xml
        "--conf", "spark.hadoop.security.authentication=simple",
        "--conf", "spark.hadoop.security.authorization=false",
        "--conf", "spark.hadoop.fs.defaultFS=file:///",
        "--conf", "spark.hadoop.fs.file.impl=org.apache.hadoop.fs.LocalFileSystem",
        "--conf", "spark.hadoop.fs.AbstractFileSystem.file.impl=org.apache.hadoop.fs.local.LocalFs",

        "--conf", "spark.sql.warehouse.dir=/app/spark-warehouse",

        # и для надёжности на драйвере/экзекьюторах
        "--conf", "spark.driver.extraJavaOptions=-Duser.name=spark -Dhadoop.user.name=spark",
        "--conf", "spark.executor.extraJavaOptions=-Duser.name=spark -Dhadoop.user.name=spark",
        "--conf", "spark.executorEnv.USER=spark",
        "--conf", "spark.executorEnv.HADOOP_USER_NAME=spark",

        "/app/target/arkasha-1.0-SNAPSHOT-jar-with-dependencies.jar",
        "lab2"
      ]
    ports:
      - "4040:4040"
    restart: "no"

